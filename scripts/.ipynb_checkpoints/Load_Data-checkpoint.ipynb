{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# for data, model, training\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from scipy import signal\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# for visuals and statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "random.seed(42)\n",
    "tf.random.set_random_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./recordings/2_jackson_13.wav', './recordings/6_george_34.wav', './recordings/7_george_5.wav', './recordings/1_yweweler_21.wav', './recordings/2_george_42.wav']\n"
     ]
    }
   ],
   "source": [
    "def get_and_shuffle_filenames(dir_name):\n",
    "    filenames = glob.glob(str(data_dir) + \"/*\")\n",
    "    random.shuffle(filenames)\n",
    "    return filenames\n",
    "\n",
    "data_dir = \"./recordings\"\n",
    "filenames = get_and_shuffle_filenames(data_dir)\n",
    "\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "\n",
    "def decode_audio(file_path):\n",
    "    # read file to get buffer                                                                                               \n",
    "    ifile = wave.open(file_path)\n",
    "    samples = ifile.getnframes()\n",
    "    audio = ifile.readframes(samples)\n",
    "\n",
    "    # convert buffer to float32 using NumPy                                                                                 \n",
    "    audio_as_np_int16 = np.frombuffer(audio, dtype=np.int16)\n",
    "    audio_as_np_float32 = audio_as_np_int16.astype(np.float32)\n",
    "    \n",
    "    # get largest absolute value\n",
    "    max_val = np.max(\n",
    "        np.absolute(\n",
    "            [np.max(audio_as_np_float32), np.min(audio_as_np_float32)]))\n",
    "    audio_normalized = audio_as_np_float32 / max_val\n",
    "\n",
    "    return audio_normalized\n",
    "\n",
    "def get_label(file_path):\n",
    "    # label is in the filename\n",
    "    parts = file_path.split(\"/\")\n",
    "    label = int(parts[2].split(\"_\")[0])\n",
    "\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499.4746666666665\n",
      "1180.9471707171701\n",
      "5632\n"
     ]
    }
   ],
   "source": [
    "# to remove outliers \n",
    "X_unfiltered = [(file_path, decode_audio(file_path)) for file_path in filenames]\n",
    "X_lengths = [audio.shape[0] for _, audio in X_unfiltered]\n",
    "\n",
    "max_length = int(np.mean(X_lengths) + 2 * np.std(X_lengths))\n",
    "max_length = int(np.floor(max_length / 256) * 256)\n",
    "print(np.mean(X_lengths))\n",
    "print(np.std(X_lengths))\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spect(signal):\n",
    "    spectogram = np.array([])\n",
    "    for i in range(int(max_length / 256)):\n",
    "        window_fft = np.fft.rfft(signal[i * 256: (i + 1) * 256])[:-1]\n",
    "        window_fft = np.abs(window_fft)\n",
    "        spectogram = np.append(spectogram, window_fft, axis=0)\n",
    "    spectogram = np.array(spectogram)\n",
    "    spectogram = librosa.amplitude_to_db(spectogram, ref=np.max)\n",
    "    return spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2312\n",
      "2816\n",
      "[2 6 7 1 2 6 6 4 3 2]\n"
     ]
    }
   ],
   "source": [
    "# padding function from\n",
    "# https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5\n",
    "\n",
    "X_full = [] # padded X values\n",
    "y_full = []\n",
    "\n",
    "numbers = [0] * 10\n",
    "\n",
    "for file_path, audio in X_unfiltered:\n",
    "    x_val = audio\n",
    "    y_val = get_label(file_path)\n",
    "    \n",
    "    if (y_val > 7): continue\n",
    "    \n",
    "    signal_length = audio.shape[0]\n",
    "    if signal_length > max_length:\n",
    "        numbers[y_val] += 1\n",
    "    else:\n",
    "        pad_len = max_length - signal_length\n",
    "        \n",
    "        x_val = np.pad(\n",
    "            x_val, (0, pad_len), \n",
    "            'constant', constant_values=(0, 0))\n",
    "        \n",
    "        spect_x = spect(x_val)\n",
    "#         spect_x = spect_x.flatten()\n",
    "        \n",
    "        X_full.append(spect_x)\n",
    "        y_full.append(y_val)\n",
    "\n",
    "X_full = np.array(X_full)\n",
    "y_full = np.array(y_full)\n",
    "\n",
    "num_samples, sample_w = X_full.shape\n",
    "print(num_samples)\n",
    "print(sample_w)\n",
    "print(y_full[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantities\n",
      "0          12\n",
      "1           9\n",
      "2           7\n",
      "3           9\n",
      "4           3\n",
      "5           8\n",
      "6          29\n",
      "7          11\n",
      "8           0\n",
      "9           0\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "# quantities = {\"y\": list(range(10)), \"quantities\": numbers}\n",
    "df = pd.DataFrame.from_dict({\"quantities\": numbers})\n",
    "print(df)\n",
    "print(sum(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_full)\n",
    "std = np.std(X_full)\n",
    "X_full = X_full - mean\n",
    "X_full = X_full / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = 3\n",
    "# cols = 3\n",
    "# n = rows * cols\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(12, 14))\n",
    "\n",
    "# for i, (audio, label) in enumerate(list(zip(X_full, y_full))[:n]):\n",
    "#     r = i // cols\n",
    "#     c = i % cols\n",
    "#     ax = axes[r][c]\n",
    "    \n",
    "#     print(audio)\n",
    "    \n",
    "#     librosa.display.specshow(audio, y_axis='mel', fmax=8000, x_axis='time', ax=axes[r][c]);\n",
    "# #     plt.title('Mel Spectrogram');\n",
    "# #     plt.colorbar(format='%+2.0f dB');\n",
    "    \n",
    "# #     ax.plot(audio)\n",
    "# #     ax.set_yticks(np.arange(-1,1.5,0.5))\n",
    "#     ax.set_title(label)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 1848\n",
      "Validation set size 231\n",
      "Test set size 233\n"
     ]
    }
   ],
   "source": [
    "tenth = int(num_samples * 0.1)\n",
    "eightyth = tenth * 8\n",
    "\n",
    "X_train = X_full[:eightyth]\n",
    "y_train = y_full[:eightyth]\n",
    "\n",
    "X_val = X_full[eightyth: eightyth + tenth]\n",
    "y_val = y_full[eightyth: eightyth + tenth]\n",
    "\n",
    "X_test = X_full[eightyth + tenth:]\n",
    "y_test = y_full[eightyth + tenth:]\n",
    "\n",
    "print('Training set size', len(X_train))\n",
    "print('Validation set size', len(X_val))\n",
    "print('Test set size', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0         1         2         3         4         5         6         7     \\\n",
      "0   0.0  2.313633  1.042296  1.135372  1.429620  2.386720  1.733977  1.525040   \n",
      "1   1.0  2.222380  0.754886  0.962842  1.097793  1.270285  2.397589  2.067042   \n",
      "2   2.0  0.049795 -0.448465 -0.100201 -0.093725  0.311123  0.236158  0.253634   \n",
      "3   7.0 -0.357687 -0.778983 -0.720297 -0.655463 -0.372127 -0.246868  0.116869   \n",
      "4   1.0  0.948393  0.989984  1.104796  1.272919  1.738875  1.430082  1.371899   \n",
      "\n",
      "       8         9     ...      2807      2808      2809      2810      2811  \\\n",
      "0  1.550332  2.230498  ... -1.036319 -1.036319 -1.036319 -1.036319 -1.036319   \n",
      "1  1.417538  1.411012  ... -1.036319 -1.036319 -1.036319 -1.036319 -1.036319   \n",
      "2 -0.046000 -0.001672  ... -1.036319 -1.036319 -1.036319 -1.036319 -1.036319   \n",
      "3 -0.285788  0.294519  ... -1.036319 -1.036319 -1.036319 -1.036319 -1.036319   \n",
      "4  1.460322  1.416337  ... -1.036319 -1.036319 -1.036319 -1.036319 -1.036319   \n",
      "\n",
      "       2812      2813      2814      2815      2816  \n",
      "0 -1.036319 -1.036319 -1.036319 -1.036319 -1.036319  \n",
      "1 -1.036319 -1.036319 -1.036319 -1.036319 -1.036319  \n",
      "2 -1.036319 -1.036319 -1.036319 -1.036319 -1.036319  \n",
      "3 -1.036319 -1.036319 -1.036319 -1.036319 -1.036319  \n",
      "4 -1.036319 -1.036319 -1.036319 -1.036319 -1.036319  \n",
      "\n",
      "[5 rows x 2817 columns]\n"
     ]
    }
   ],
   "source": [
    "flattened_data = {}\n",
    "i = 0\n",
    "for x, y in zip(X_test, y_test):\n",
    "    flattened_data[i] = np.concatenate(([y], x.flatten()))\n",
    "    i += 1\n",
    "    \n",
    "df = pd.DataFrame.from_dict(flattened_data, orient='index')\n",
    "print(df.head())\n",
    "df.to_csv(\"my_model_test3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
