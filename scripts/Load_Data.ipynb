{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# for data, model, training\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from scipy import signal\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# for visuals and statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "random.seed(42)\n",
    "tf.random.set_random_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./recordings/2_jackson_13.wav', './recordings/6_george_34.wav', './recordings/7_george_5.wav', './recordings/1_yweweler_21.wav', './recordings/2_george_42.wav']\n"
     ]
    }
   ],
   "source": [
    "def get_and_shuffle_filenames(dir_name):\n",
    "    filenames = glob.glob(str(data_dir) + \"/*\")\n",
    "    random.shuffle(filenames)\n",
    "    return filenames\n",
    "\n",
    "data_dir = \"./recordings\"\n",
    "filenames = get_and_shuffle_filenames(data_dir)\n",
    "\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "\n",
    "def decode_audio(file_path):\n",
    "    # read file to get buffer                                                                                               \n",
    "    ifile = wave.open(file_path)\n",
    "    samples = ifile.getnframes()\n",
    "    audio = ifile.readframes(samples)\n",
    "\n",
    "    # convert buffer to float32 using NumPy                                                                                 \n",
    "    audio_as_np_int16 = np.frombuffer(audio, dtype=np.int16)\n",
    "    audio_as_np_float32 = audio_as_np_int16.astype(np.float32)\n",
    "    \n",
    "    # get largest absolute value\n",
    "    max_val = np.max(\n",
    "        np.absolute(\n",
    "            [np.max(audio_as_np_float32), np.min(audio_as_np_float32)]))\n",
    "    audio_normalized = audio_as_np_float32 / max_val\n",
    "\n",
    "    return audio_normalized\n",
    "\n",
    "def get_label(file_path):\n",
    "    # label is in the filename\n",
    "    parts = file_path.split(\"/\")\n",
    "    label = int(parts[2].split(\"_\")[0])\n",
    "\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499.4746666666665\n",
      "1180.9471707171701\n",
      "5861\n"
     ]
    }
   ],
   "source": [
    "# to remove outliers \n",
    "X_unfiltered = [(file_path, decode_audio(file_path)) for file_path in filenames]\n",
    "X_lengths = [audio.shape[0] for _, audio in X_unfiltered]\n",
    "\n",
    "max_length = int(np.mean(X_lengths) + 2 * np.std(X_lengths))\n",
    "print(np.mean(X_lengths))\n",
    "print(np.std(X_lengths))\n",
    "print(max_length)\n",
    "max_length = 5888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spect(signal):\n",
    "    spectogram = np.array([])\n",
    "    for i in range(23):\n",
    "        window_fft = np.fft.rfft(signal[i * 256: (i + 1) * 256])[:-1]\n",
    "        window_fft = np.abs(window_fft)\n",
    "        spectogram = np.append(spectogram, window_fft, axis=0)\n",
    "    spectogram = np.array(spectogram)\n",
    "    spectogram = librosa.amplitude_to_db(spectogram, ref=np.max)\n",
    "    return spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2329\n",
      "2944\n",
      "[2 6 7 1 2 6 6 4 3 2]\n"
     ]
    }
   ],
   "source": [
    "# padding function from\n",
    "# https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5\n",
    "\n",
    "X_full = [] # padded X values\n",
    "y_full = []\n",
    "\n",
    "numbers = [0] * 10\n",
    "\n",
    "for file_path, audio in X_unfiltered:\n",
    "    x_val = audio\n",
    "    y_val = get_label(file_path)\n",
    "    \n",
    "    if (y_val > 7): continue\n",
    "    \n",
    "    signal_length = audio.shape[0]\n",
    "    if signal_length > max_length:\n",
    "        numbers[y_val] += 1\n",
    "    else:\n",
    "        pad_len = max_length - signal_length\n",
    "        \n",
    "        x_val = np.pad(\n",
    "            x_val, (0, pad_len), \n",
    "            'constant', constant_values=(0, 0))\n",
    "        \n",
    "        spect_x = spect(x_val)\n",
    "#         spect_x = spect_x.flatten()\n",
    "        \n",
    "        X_full.append(spect_x)\n",
    "        y_full.append(y_val)\n",
    "\n",
    "X_full = np.array(X_full)\n",
    "y_full = np.array(y_full)\n",
    "\n",
    "num_samples, sample_w = X_full.shape\n",
    "print(num_samples)\n",
    "print(sample_w)\n",
    "print(y_full[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantities\n",
      "0          10\n",
      "1           8\n",
      "2           6\n",
      "3           5\n",
      "4           3\n",
      "5           6\n",
      "6          22\n",
      "7          11\n",
      "8           0\n",
      "9           0\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "# quantities = {\"y\": list(range(10)), \"quantities\": numbers}\n",
    "df = pd.DataFrame.from_dict({\"quantities\": numbers})\n",
    "print(df)\n",
    "print(sum(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_full)\n",
    "std = np.std(X_full)\n",
    "X_full = X_full - mean\n",
    "X_full = X_full / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = 3\n",
    "# cols = 3\n",
    "# n = rows * cols\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(12, 14))\n",
    "\n",
    "# for i, (audio, label) in enumerate(list(zip(X_full, y_full))[:n]):\n",
    "#     r = i // cols\n",
    "#     c = i % cols\n",
    "#     ax = axes[r][c]\n",
    "    \n",
    "#     print(audio)\n",
    "    \n",
    "#     librosa.display.specshow(audio, y_axis='mel', fmax=8000, x_axis='time', ax=axes[r][c]);\n",
    "# #     plt.title('Mel Spectrogram');\n",
    "# #     plt.colorbar(format='%+2.0f dB');\n",
    "    \n",
    "# #     ax.plot(audio)\n",
    "# #     ax.set_yticks(np.arange(-1,1.5,0.5))\n",
    "#     ax.set_title(label)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 1856\n",
      "Validation set size 232\n",
      "Test set size 241\n"
     ]
    }
   ],
   "source": [
    "tenth = int(num_samples * 0.1)\n",
    "eightyth = tenth * 8\n",
    "\n",
    "X_train = X_full[:eightyth]\n",
    "y_train = y_full[:eightyth]\n",
    "\n",
    "X_val = X_full[eightyth: eightyth + tenth]\n",
    "y_val = y_full[eightyth: eightyth + tenth]\n",
    "\n",
    "X_test = X_full[eightyth + tenth:]\n",
    "y_test = y_full[eightyth + tenth:]\n",
    "\n",
    "print('Training set size', len(X_train))\n",
    "print('Validation set size', len(X_val))\n",
    "print('Test set size', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0         1         2         3         4         5         6         7     \\\n",
      "0   4.0 -0.517063 -0.145395  0.345380  0.014779 -0.157025 -0.103307 -0.191867   \n",
      "1   2.0  0.787242  0.590388  0.147761  0.202116  0.831150  0.706009  0.825241   \n",
      "2   7.0  0.246638 -0.295067  0.013261  0.180662  0.257957  0.020789  0.279846   \n",
      "3   1.0  0.172252  0.707328  1.043602  1.292135  1.502515  2.028182  2.307660   \n",
      "4   4.0  1.042133  1.023080  0.802510  0.967628  1.978160  1.311670  1.222563   \n",
      "\n",
      "       8         9     ...      2935      2936      2937      2938      2939  \\\n",
      "0 -0.457938 -0.199374  ... -0.993144 -0.993144 -0.993144 -0.993144 -0.993144   \n",
      "1  1.031756  0.763968  ... -0.993144 -0.993144 -0.993144 -0.993144 -0.993144   \n",
      "2  0.320586  0.111707  ... -0.993144 -0.993144 -0.993144 -0.993144 -0.993144   \n",
      "3  1.662410  1.580116  ... -0.993144 -0.993144 -0.993144 -0.993144 -0.993144   \n",
      "4  1.444402  2.176260  ... -0.993144 -0.993144 -0.993144 -0.993144 -0.993144   \n",
      "\n",
      "       2940      2941      2942      2943      2944  \n",
      "0 -0.993144 -0.993144 -0.993144 -0.993144 -0.993144  \n",
      "1 -0.993144 -0.993144 -0.993144 -0.993144 -0.993144  \n",
      "2 -0.993144 -0.993144 -0.993144 -0.993144 -0.993144  \n",
      "3 -0.993144 -0.993144 -0.993144 -0.993144 -0.993144  \n",
      "4 -0.993144 -0.993144 -0.993144 -0.993144 -0.993144  \n",
      "\n",
      "[5 rows x 2945 columns]\n"
     ]
    }
   ],
   "source": [
    "flattened_data = {}\n",
    "i = 0\n",
    "for x, y in zip(X_test, y_test):\n",
    "    flattened_data[i] = np.concatenate(([y], x.flatten()))\n",
    "    i += 1\n",
    "    \n",
    "df = pd.DataFrame.from_dict(flattened_data, orient='index')\n",
    "print(df.head())\n",
    "df.to_csv(\"my_model_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
