{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c5d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# for data, model, training\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import basics\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "random.seed(42)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c14066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./recordings/2_jackson_13.wav', './recordings/6_george_34.wav', './recordings/7_george_5.wav', './recordings/1_yweweler_21.wav', './recordings/2_george_42.wav']\n"
     ]
    }
   ],
   "source": [
    "filenames = basics.get_and_shuffle_filenames(\"./recordings\")\n",
    "\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ba658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5632\n"
     ]
    }
   ],
   "source": [
    "X_unfiltered = [(file_path, basics.decode_audio(file_path)) for file_path in filenames]\n",
    "\n",
    "# to remove outliers \n",
    "max_length = basics.get_max_length(X_unfiltered)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0b2050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2312, 2816)\n",
      "2312\n",
      "2816\n",
      "[2 6 7 1 2 6 6 4 3 2]\n"
     ]
    }
   ],
   "source": [
    "X_full = [] # padded X values 0-7\n",
    "y_full = []\n",
    "\n",
    "numbers = [0] * 8\n",
    "\n",
    "for file_path, audio in X_unfiltered:\n",
    "    x_val = audio\n",
    "    y_val = basics.get_label(file_path)\n",
    "    signal_length = audio.shape[0]\n",
    "    \n",
    "    if y_val > 7:\n",
    "        continue\n",
    "    if signal_length > max_length:\n",
    "        numbers[y_val] += 1\n",
    "        continue\n",
    "        \n",
    "    x_val = np.pad(\n",
    "        x_val, (0, max_length - signal_length), \n",
    "        'constant', constant_values=(0, 0))\n",
    "\n",
    "    x_spect = basics.spect(x_val, max_length)\n",
    "    x_spect = x_spect.flatten()\n",
    "\n",
    "    X_full.append(x_spect)\n",
    "    y_full.append(y_val)\n",
    "\n",
    "X_full = np.array(X_full)\n",
    "y_full = np.array(y_full)\n",
    "\n",
    "print(X_full.shape)\n",
    "\n",
    "num_samples, sample_w = X_full.shape\n",
    "print(num_samples)\n",
    "print(sample_w)\n",
    "\n",
    "print(y_full[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5cda69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantities\n",
      "0          12\n",
      "1           9\n",
      "2           7\n",
      "3           9\n",
      "4           3\n",
      "5           8\n",
      "6          29\n",
      "7          11\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "# dropped outliers\n",
    "df = pd.DataFrame.from_dict({\"quantities\": numbers})\n",
    "print(df)\n",
    "print(sum(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c6c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 1848\n",
      "Validation set size 231\n",
      "Test set size 233\n"
     ]
    }
   ],
   "source": [
    "# normalize data\n",
    "X_full = basics.normalize_arr(X_full)\n",
    "\n",
    "# partition into 80:10:10\n",
    "partitions = basics.split_full(X_full, y_full)\n",
    "\n",
    "X_train, y_train = partitions[0]\n",
    "X_val, y_val = partitions[1]\n",
    "X_test, y_test = partitions[2]\n",
    "\n",
    "print('Training set size', len(X_train))\n",
    "print('Validation set size', len(X_val))\n",
    "print('Test set size', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca02ea9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (None, 128, 22, 1)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 125, 19, 64)       1088      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 125, 19, 64)       0         \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 62, 9, 64)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 59, 6, 16)         16400     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 59, 6, 16)         0         \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 29, 3, 16)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1392)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1392)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 70)                97510     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 568       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,566\n",
      "Trainable params: 115,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# INPUTS ARE NORMALIZED\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Reshape((128, 22, 1), input_shape=(sample_w,)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (4, 4), activation='relu', input_shape=(128, 22, 1)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.AveragePooling2D(2,2))\n",
    "model.add(tf.keras.layers.Conv2D(16, (4, 4), activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.AveragePooling2D(2,2))\n",
    " \n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.15))    \n",
    "model.add(tf.keras.layers.Dense(70, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c0b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4e4acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 1.9315 - accuracy: 0.2587 - val_loss: 1.6350 - val_accuracy: 0.4416\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 1.2088 - accuracy: 0.5758 - val_loss: 0.8931 - val_accuracy: 0.7186\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.7928 - accuracy: 0.7143 - val_loss: 0.7109 - val_accuracy: 0.7835\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.5717 - accuracy: 0.8025 - val_loss: 0.4663 - val_accuracy: 0.8918\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 0.4119 - accuracy: 0.8631 - val_loss: 0.4300 - val_accuracy: 0.8745\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.3271 - accuracy: 0.8912 - val_loss: 0.4189 - val_accuracy: 0.8831\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 0.2622 - accuracy: 0.9123 - val_loss: 0.3094 - val_accuracy: 0.8961\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.2164 - accuracy: 0.9307 - val_loss: 0.2860 - val_accuracy: 0.9048\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 4s 68ms/step - loss: 0.1926 - accuracy: 0.9367 - val_loss: 0.2843 - val_accuracy: 0.9091\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.1597 - accuracy: 0.9459 - val_loss: 0.2508 - val_accuracy: 0.9307\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 0.1533 - accuracy: 0.9470 - val_loss: 0.2588 - val_accuracy: 0.9307\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.1447 - accuracy: 0.9481 - val_loss: 0.2925 - val_accuracy: 0.9134\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 0.1346 - accuracy: 0.9600 - val_loss: 0.2627 - val_accuracy: 0.9177\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 0.1272 - accuracy: 0.9562 - val_loss: 0.2399 - val_accuracy: 0.9394\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.1051 - accuracy: 0.9632 - val_loss: 0.2400 - val_accuracy: 0.9351\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.0997 - accuracy: 0.9713 - val_loss: 0.2173 - val_accuracy: 0.9307\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.0994 - accuracy: 0.9621 - val_loss: 0.3031 - val_accuracy: 0.9221\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 0.0818 - accuracy: 0.9719 - val_loss: 0.2331 - val_accuracy: 0.9307\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 4s 67ms/step - loss: 0.0799 - accuracy: 0.9735 - val_loss: 0.2473 - val_accuracy: 0.9394\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 0.0670 - accuracy: 0.9778 - val_loss: 0.2374 - val_accuracy: 0.9264\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.0690 - accuracy: 0.9756 - val_loss: 0.2792 - val_accuracy: 0.9351\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 0.0812 - accuracy: 0.9713 - val_loss: 0.2520 - val_accuracy: 0.9351\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 0.2481 - val_accuracy: 0.9307\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.0485 - accuracy: 0.9832 - val_loss: 0.2495 - val_accuracy: 0.9437\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 4s 67ms/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.2786 - val_accuracy: 0.9307\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.0355 - accuracy: 0.9881 - val_loss: 0.2384 - val_accuracy: 0.9394\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 5s 90ms/step - loss: 0.0592 - accuracy: 0.9800 - val_loss: 0.2477 - val_accuracy: 0.9524\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 0.0410 - accuracy: 0.9865 - val_loss: 0.2133 - val_accuracy: 0.9351\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 0.0419 - accuracy: 0.9838 - val_loss: 0.2660 - val_accuracy: 0.9307\n",
      "Epoch 30/30\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 0.0409 - accuracy: 0.9843 - val_loss: 0.2922 - val_accuracy: 0.9351\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ce3853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1567 - accuracy: 0.9528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15665334463119507, 0.9527897238731384]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc10ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminewu/Documents/6115/II/Spoken_Digits/scripts/venv/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:238: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  trainable=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_reshape  (None, 128, 22, 1)       1         \n",
      " _1 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 125, 19, 64)      2114      \n",
      " 2 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dropout  (None, 125, 19, 64)      1         \n",
      " _3 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_average  (None, 62, 9, 64)        1         \n",
      " _pooling2d_2 (PruneLowMagni                                     \n",
      " tude)                                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 59, 6, 16)        32786     \n",
      " 3 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_dropout  (None, 59, 6, 16)        1         \n",
      " _4 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_average  (None, 29, 3, 16)        1         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminewu/Documents/6115/II/Spoken_Digits/scripts/venv/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:218: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  aggregation=tf.VariableAggregation.MEAN)\n",
      "/Users/jasminewu/Documents/6115/II/Spoken_Digits/scripts/venv/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  aggregation=tf.VariableAggregation.MEAN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _pooling2d_3 (PruneLowMagni                                     \n",
      " tude)                                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 1392)             1         \n",
      " _1 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dropout  (None, 1392)             1         \n",
      " _5 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_2  (None, 70)               194952    \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_3  (None, 8)                1130      \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 230,989\n",
      "Trainable params: 115,566\n",
      "Non-trainable params: 115,423\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = len(X_train)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6763a0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "13/13 [==============================] - 8s 320ms/step - loss: 0.0308 - accuracy: 0.9910 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 2/15\n",
      "13/13 [==============================] - 4s 315ms/step - loss: 0.0413 - accuracy: 0.9892 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 3/15\n",
      "13/13 [==============================] - 4s 308ms/step - loss: 0.0316 - accuracy: 0.9886 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "13/13 [==============================] - 4s 302ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0127 - val_accuracy: 0.9946\n",
      "Epoch 5/15\n",
      "13/13 [==============================] - 4s 304ms/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.0164 - val_accuracy: 0.9946\n",
      "Epoch 6/15\n",
      "13/13 [==============================] - 4s 311ms/step - loss: 0.0226 - accuracy: 0.9910 - val_loss: 0.0185 - val_accuracy: 0.9946\n",
      "Epoch 7/15\n",
      "13/13 [==============================] - 4s 307ms/step - loss: 0.0201 - accuracy: 0.9946 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "13/13 [==============================] - 4s 324ms/step - loss: 0.2172 - accuracy: 0.9260 - val_loss: 0.2824 - val_accuracy: 0.9351\n",
      "Epoch 9/15\n",
      "13/13 [==============================] - 4s 319ms/step - loss: 0.2509 - accuracy: 0.9308 - val_loss: 0.1312 - val_accuracy: 0.9676\n",
      "Epoch 10/15\n",
      "13/13 [==============================] - 4s 306ms/step - loss: 0.1429 - accuracy: 0.9669 - val_loss: 0.0969 - val_accuracy: 0.9784\n",
      "Epoch 11/15\n",
      "13/13 [==============================] - 4s 313ms/step - loss: 0.1016 - accuracy: 0.9784 - val_loss: 0.0783 - val_accuracy: 0.9730\n",
      "Epoch 12/15\n",
      "13/13 [==============================] - 4s 339ms/step - loss: 0.0875 - accuracy: 0.9753 - val_loss: 0.0666 - val_accuracy: 0.9892\n",
      "Epoch 13/15\n",
      "13/13 [==============================] - 4s 313ms/step - loss: 0.0717 - accuracy: 0.9832 - val_loss: 0.0675 - val_accuracy: 0.9730\n",
      "Epoch 14/15\n",
      "13/13 [==============================] - 4s 313ms/step - loss: 0.0656 - accuracy: 0.9838 - val_loss: 0.0604 - val_accuracy: 0.9838\n",
      "Epoch 15/15\n",
      "13/13 [==============================] - 4s 320ms/step - loss: 0.0606 - accuracy: 0.9844 - val_loss: 0.0581 - val_accuracy: 0.9730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79d4c2dc10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(X_train, y_train,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85e12d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1560 - accuracy: 0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1560189127922058, 0.9570815563201904]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_pruning.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36889e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved pruned Keras model to: /var/folders/vs/b_y62_cj4859tj4h1ch0glg80000gn/T/tmpgla1a4f4.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee8fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
