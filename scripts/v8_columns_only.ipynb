{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef03eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# for data, model, training\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import signal\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# for visuals and statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "random.seed(42)\n",
    "tf.random.set_random_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0965a661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./recordings/2_jackson_13.wav', './recordings/6_george_34.wav', './recordings/7_george_5.wav', './recordings/1_yweweler_21.wav', './recordings/2_george_42.wav']\n"
     ]
    }
   ],
   "source": [
    "def get_and_shuffle_filenames(dir_name):\n",
    "    filenames = glob.glob(str(data_dir) + \"/*\")\n",
    "    random.shuffle(filenames)\n",
    "    return filenames\n",
    "\n",
    "data_dir = \"./recordings\"\n",
    "filenames = get_and_shuffle_filenames(data_dir)\n",
    "\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fa6526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "\n",
    "def decode_audio(file_path):\n",
    "    # read file to get buffer                                                                                               \n",
    "    ifile = wave.open(file_path)\n",
    "    samples = ifile.getnframes()\n",
    "    audio = ifile.readframes(samples)\n",
    "\n",
    "    # convert buffer to float32 using NumPy                                                                                 \n",
    "    audio_as_np_int16 = np.frombuffer(audio, dtype=np.int16)\n",
    "    audio_as_np_float32 = audio_as_np_int16.astype(np.float32)\n",
    "    \n",
    "    # get largest absolute value\n",
    "    max_val = np.max(\n",
    "        np.absolute(\n",
    "            [np.max(audio_as_np_float32), np.min(audio_as_np_float32)]))\n",
    "    audio_normalized = audio_as_np_float32 / max_val\n",
    "\n",
    "    return audio_normalized\n",
    "\n",
    "def get_label(file_path):\n",
    "    # label is in the filename\n",
    "    parts = file_path.split(\"/\")\n",
    "    label = int(parts[2].split(\"_\")[0])\n",
    "\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f2234b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499.4746666666665\n",
      "1180.9471707171701\n",
      "5888\n"
     ]
    }
   ],
   "source": [
    "# to remove outliers \n",
    "X_unfiltered = [(file_path, decode_audio(file_path)) for file_path in filenames]\n",
    "X_lengths = [audio.shape[0] for _, audio in X_unfiltered]\n",
    "\n",
    "max_length = int(np.mean(X_lengths) + 2 * np.std(X_lengths))\n",
    "max_length = int(np.ceil(5861 / 256) * 256)\n",
    "print(np.mean(X_lengths))\n",
    "print(np.std(X_lengths))\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c7fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spect(signal):\n",
    "    spectogram = []\n",
    "    for i in range(23):\n",
    "        window_fft = np.fft.rfft(signal[i * 256: (i + 1) * 256])[:-1]\n",
    "        window_fft = list(np.abs(window_fft))\n",
    "        spectogram.append(window_fft)\n",
    "    spectogram = np.array(spectogram)\n",
    "    spectogram = librosa.amplitude_to_db(spectogram, ref=np.max)\n",
    "    spectogram = spectogram / 20\n",
    "    return spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "595c34e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329, 2944)\n",
      "2329\n",
      "2944\n",
      "[2 6 7 1 2 6 6 4 3 2]\n"
     ]
    }
   ],
   "source": [
    "# padding function from\n",
    "# https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5\n",
    "\n",
    "X_full = [] # padded X values\n",
    "y_full = []\n",
    "\n",
    "numbers = [0] * 10\n",
    "\n",
    "for file_path, audio in X_unfiltered:\n",
    "    x_val = audio\n",
    "    y_val = get_label(file_path)\n",
    "    \n",
    "    if y_val > 7:\n",
    "        continue\n",
    "    \n",
    "    signal_length = audio.shape[0]\n",
    "    if signal_length > max_length:\n",
    "        numbers[y_val] += 1\n",
    "    else:\n",
    "        pad_len = max_length - signal_length\n",
    "        \n",
    "        x_val = np.pad(\n",
    "            x_val, (0, pad_len), \n",
    "            'constant', constant_values=(0, 0))\n",
    "        \n",
    "#         mel_x = mel_spec(x_val)\n",
    "        s_x = spect(x_val)\n",
    "        s_x = s_x.flatten()\n",
    "        \n",
    "        X_full.append(s_x)\n",
    "        y_full.append(y_val)\n",
    "\n",
    "X_full = np.array(X_full)\n",
    "y_full = np.array(y_full)\n",
    "\n",
    "print(X_full.shape)\n",
    "\n",
    "num_samples, sample_w = X_full.shape\n",
    "print(num_samples)\n",
    "print(sample_w)\n",
    "\n",
    "print(y_full[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3863450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantities\n",
      "0          10\n",
      "1           8\n",
      "2           6\n",
      "3           5\n",
      "4           3\n",
      "5           6\n",
      "6          22\n",
      "7          11\n",
      "8           0\n",
      "9           0\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "# quantities = {\"y\": list(range(10)), \"quantities\": numbers}\n",
    "df = pd.DataFrame.from_dict({\"quantities\": numbers})\n",
    "print(df)\n",
    "print(sum(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1934b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_full)\n",
    "std = np.std(X_full)\n",
    "X_full = X_full - mean\n",
    "X_full = X_full / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cea8e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = 3\n",
    "# cols = 3\n",
    "# n = rows * cols\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(12, 14))\n",
    "\n",
    "# for i, (audio, label) in enumerate(list(zip(X_full, y_full))[:n]):\n",
    "#     r = i // cols\n",
    "#     c = i % cols\n",
    "#     ax = axes[r][c]\n",
    "    \n",
    "#     librosa.display.specshow(audio, sr=8000, hop_length=256, x_axis='time', ax=axes[r][c])\n",
    "# #     librosa.display.specshow(audio, y_axis='mel', fmax=8000, x_axis='time', ax=axes[r][c]);\n",
    "# #     plt.title('Mel Spectrogram');\n",
    "# #     plt.colorbar(format='%+2.0f dB');\n",
    "    \n",
    "# #     ax.plot(audio)\n",
    "# #     ax.set_yticks(np.arange(-1,1.5,0.5))\n",
    "#     ax.set_title(label)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c690d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 1856\n",
      "Validation set size 232\n",
      "Test set size 241\n"
     ]
    }
   ],
   "source": [
    "tenth = int(num_samples * 0.1)\n",
    "eightyth = tenth * 8\n",
    "\n",
    "X_train = X_full[:eightyth]\n",
    "y_train = y_full[:eightyth]\n",
    "\n",
    "X_val = X_full[eightyth: eightyth + tenth]\n",
    "y_val = y_full[eightyth: eightyth + tenth]\n",
    "\n",
    "X_test = X_full[eightyth + tenth:]\n",
    "y_test = y_full[eightyth + tenth:]\n",
    "\n",
    "print('Training set size', len(X_train))\n",
    "print('Validation set size', len(X_val))\n",
    "print('Test set size', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5e11321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 128, 23, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 125, 20, 64)       1088      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 125, 20, 64)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 62, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 59, 7, 16)         16400     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 59, 7, 16)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 29, 3, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1392)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1392)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 70)                97510     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 568       \n",
      "=================================================================\n",
      "Total params: 115,566\n",
      "Trainable params: 115,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# INPUTS ARE NORMALIZED\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Reshape((128, 23, 1), input_shape=(sample_w,)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (4, 4), activation='relu', input_shape=(128, 23, 1)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.AveragePooling2D(2,2))\n",
    "model.add(tf.keras.layers.Conv2D(16, (4, 4), activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.AveragePooling2D(2,2))\n",
    " \n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.15))    \n",
    "model.add(tf.keras.layers.Dense(70, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ca173dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1855cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1856 samples, validate on 232 samples\n",
      "Epoch 1/30\n",
      "1856/1856 [==============================] - 4s 2ms/sample - loss: 1.9413 - acc: 0.2489 - val_loss: 1.6561 - val_acc: 0.3578\n",
      "Epoch 2/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 1.3281 - acc: 0.5286 - val_loss: 1.0597 - val_acc: 0.6422\n",
      "Epoch 3/30\n",
      "1856/1856 [==============================] - 5s 2ms/sample - loss: 0.9074 - acc: 0.6810 - val_loss: 0.7328 - val_acc: 0.7543\n",
      "Epoch 4/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.6422 - acc: 0.7807 - val_loss: 0.6689 - val_acc: 0.7414\n",
      "Epoch 5/30\n",
      "1856/1856 [==============================] - 5s 2ms/sample - loss: 0.4902 - acc: 0.8249 - val_loss: 0.5045 - val_acc: 0.8060\n",
      "Epoch 6/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.3956 - acc: 0.8680 - val_loss: 0.3813 - val_acc: 0.8664\n",
      "Epoch 7/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.3150 - acc: 0.8912 - val_loss: 0.3816 - val_acc: 0.8793\n",
      "Epoch 8/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.2915 - acc: 0.9046 - val_loss: 0.3083 - val_acc: 0.9052\n",
      "Epoch 9/30\n",
      "1856/1856 [==============================] - 6s 3ms/sample - loss: 0.2220 - acc: 0.9267 - val_loss: 0.2926 - val_acc: 0.9052\n",
      "Epoch 10/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.1901 - acc: 0.9353 - val_loss: 0.2896 - val_acc: 0.9009\n",
      "Epoch 11/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.1881 - acc: 0.9327 - val_loss: 0.2899 - val_acc: 0.9052\n",
      "Epoch 12/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.1560 - acc: 0.9510 - val_loss: 0.2537 - val_acc: 0.9138\n",
      "Epoch 13/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.1313 - acc: 0.9574 - val_loss: 0.2288 - val_acc: 0.9353\n",
      "Epoch 14/30\n",
      "1856/1856 [==============================] - 5s 2ms/sample - loss: 0.1436 - acc: 0.9558 - val_loss: 0.2174 - val_acc: 0.9310\n",
      "Epoch 15/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.1277 - acc: 0.9537 - val_loss: 0.2128 - val_acc: 0.9267\n",
      "Epoch 16/30\n",
      "1856/1856 [==============================] - 5s 2ms/sample - loss: 0.1022 - acc: 0.9666 - val_loss: 0.2247 - val_acc: 0.9310\n",
      "Epoch 17/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.0901 - acc: 0.9677 - val_loss: 0.2461 - val_acc: 0.9267\n",
      "Epoch 18/30\n",
      "1856/1856 [==============================] - 5s 3ms/sample - loss: 0.1015 - acc: 0.9671 - val_loss: 0.2419 - val_acc: 0.9224\n",
      "Epoch 19/30\n",
      "1152/1856 [=================>............] - ETA: 1s - loss: 0.0829 - acc: 0.9748"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f94d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d301d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "all_labels = list(range(8))\n",
    "\n",
    "confusion_mtx = tf.math.confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=all_labels,\n",
    "            yticklabels=all_labels,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10826bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"v8_small_7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f97fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
