{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4859548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import wave\n",
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f726f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "['recordings/8_yweweler_19.wav', 'recordings/9_george_10.wav', 'recordings/8_nicolas_21.wav', 'recordings/8_yweweler_8.wav', 'recordings/4_george_1.wav']\n"
     ]
    }
   ],
   "source": [
    "# shuffle filenames\n",
    "\n",
    "data_dir = \"recordings\"\n",
    "\n",
    "filenames = glob.glob(str(data_dir) + \"/*\")\n",
    "random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "\n",
    "print(num_samples)\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0840a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "\n",
    "def decode_audio(file_path):\n",
    "    # Read file to get buffer                                                                                               \n",
    "    ifile = wave.open(file_path)\n",
    "    samples = ifile.getnframes()\n",
    "    audio = ifile.readframes(samples)\n",
    "\n",
    "    # Convert buffer to float32 using NumPy                                                                                 \n",
    "    audio_as_np_int16 = np.frombuffer(audio, dtype=np.int16)\n",
    "    audio_as_np_float32 = audio_as_np_int16.astype(np.float32)\n",
    "\n",
    "    # Normalise float32 array so that values are between -1.0 and +1.0                                                      \n",
    "    max_int16 = 2**15\n",
    "    audio_normalized = audio_as_np_float32 / max_int16\n",
    "        \n",
    "    return audio_normalized\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = file_path.split(\"/\")\n",
    "    \n",
    "    label = int(parts[1].split(\"_\")[0])\n",
    "    \n",
    "    # Note: You'll use indexing here instead of tuple unpacking to enable this\n",
    "    # to work in a TensorFlow graph.\n",
    "    return label\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    waveform = decode_audio(file_path)\n",
    "    return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b79f56e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499.4746666666665\n",
      "1180.9471707171701\n",
      "7042\n"
     ]
    }
   ],
   "source": [
    "labeled = []\n",
    "\n",
    "lengths = np.array([])\n",
    "\n",
    "for file_path in filenames:\n",
    "    x_val = decode_audio(file_path)\n",
    "    y_val = get_label(file_path)\n",
    "    labeled.append((x_val, y_val))\n",
    "    lengths = np.append(lengths, x_val.shape[0])\n",
    "\n",
    "max_length = int(np.mean(lengths) + 3 * np.std(lengths))\n",
    "print(np.mean(lengths))\n",
    "print(np.std(lengths))\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ec43109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2965\n"
     ]
    }
   ],
   "source": [
    "# padding function from\n",
    "# https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5\n",
    "\n",
    "X_full = []\n",
    "y_full = []\n",
    "\n",
    "numbers = [0] * 10\n",
    "\n",
    "for x_val, y_val in labeled:\n",
    "    signal_length = x_val.shape[0]\n",
    "    if signal_length > max_length:\n",
    "        numbers[y_val] += 1\n",
    "    else:\n",
    "        pad_begin_len = random.randint(0, max_length - signal_length)\n",
    "        pad_end_len = max_length - signal_length - pad_begin_len\n",
    "        \n",
    "        new_x_val = np.pad(\n",
    "            x_val, (pad_begin_len, pad_end_len), \n",
    "            'constant', constant_values=(0, 0))\n",
    "        \n",
    "        X_full.append(new_x_val)\n",
    "        y_full.append(y_val)\n",
    "\n",
    "X_full = np.array(X_full)\n",
    "y_full = np.array(y_full)\n",
    "\n",
    "num_samples = X_full.shape[0]\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1350616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y  quantities\n",
      "0  0           4\n",
      "1  1           3\n",
      "2  2           5\n",
      "3  3           3\n",
      "4  4           1\n",
      "5  5           3\n",
      "6  6           2\n",
      "7  7           7\n",
      "8  8           3\n",
      "9  9           4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quantities = {\"y\": list(range(10)), \"quantities\": numbers}\n",
    "df = pd.DataFrame.from_dict(quantities)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e77497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 2368\n",
      "Validation set size 296\n",
      "Test set size 301\n"
     ]
    }
   ],
   "source": [
    "tenth = int(num_samples * 0.1)\n",
    "eightyth = tenth * 8\n",
    "\n",
    "X_train = X_full[:eightyth]\n",
    "y_train = y_full[:eightyth]\n",
    "\n",
    "X_val = X_full[eightyth: eightyth + tenth]\n",
    "y_val = y_full[eightyth: eightyth + tenth]\n",
    "\n",
    "X_test = X_full[eightyth + tenth:]\n",
    "y_test = y_full[eightyth + tenth:]\n",
    "\n",
    "print('Training set size', len(X_train))\n",
    "print('Validation set size', len(X_val))\n",
    "print('Test set size', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a5a438f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 300)               2112900   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,144,010\n",
      "Trainable params: 2,144,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\", input_shape=(7042,)))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# alternatively:\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     keras.layers.Dense(300, activation=\"relu\"),\n",
    "#     keras.layers.Dense(100, activation=\"relu\"),\n",
    "#     keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44f1598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bd417e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 2.3042 - accuracy: 0.0891 - val_loss: 2.3022 - val_accuracy: 0.0980\n",
      "Epoch 2/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.3010 - accuracy: 0.0933 - val_loss: 2.3027 - val_accuracy: 0.1115\n",
      "Epoch 3/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2980 - accuracy: 0.1047 - val_loss: 2.3031 - val_accuracy: 0.1250\n",
      "Epoch 4/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2950 - accuracy: 0.1102 - val_loss: 2.3035 - val_accuracy: 0.1182\n",
      "Epoch 5/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2922 - accuracy: 0.1254 - val_loss: 2.3038 - val_accuracy: 0.1149\n",
      "Epoch 6/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2895 - accuracy: 0.1427 - val_loss: 2.3041 - val_accuracy: 0.1014\n",
      "Epoch 7/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2867 - accuracy: 0.1541 - val_loss: 2.3043 - val_accuracy: 0.1014\n",
      "Epoch 8/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2839 - accuracy: 0.1601 - val_loss: 2.3044 - val_accuracy: 0.0946\n",
      "Epoch 9/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2811 - accuracy: 0.1782 - val_loss: 2.3045 - val_accuracy: 0.0912\n",
      "Epoch 10/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2784 - accuracy: 0.1854 - val_loss: 2.3047 - val_accuracy: 0.0912\n",
      "Epoch 11/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2755 - accuracy: 0.2057 - val_loss: 2.3047 - val_accuracy: 0.1014\n",
      "Epoch 12/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2726 - accuracy: 0.2145 - val_loss: 2.3047 - val_accuracy: 0.1047\n",
      "Epoch 13/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2697 - accuracy: 0.2318 - val_loss: 2.3049 - val_accuracy: 0.1081\n",
      "Epoch 14/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2668 - accuracy: 0.2416 - val_loss: 2.3048 - val_accuracy: 0.1047\n",
      "Epoch 15/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2638 - accuracy: 0.2644 - val_loss: 2.3049 - val_accuracy: 0.1014\n",
      "Epoch 16/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2607 - accuracy: 0.2665 - val_loss: 2.3049 - val_accuracy: 0.0980\n",
      "Epoch 17/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2575 - accuracy: 0.2842 - val_loss: 2.3047 - val_accuracy: 0.1014\n",
      "Epoch 18/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2543 - accuracy: 0.2943 - val_loss: 2.3048 - val_accuracy: 0.1047\n",
      "Epoch 19/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2510 - accuracy: 0.3104 - val_loss: 2.3047 - val_accuracy: 0.1047\n",
      "Epoch 20/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2476 - accuracy: 0.3247 - val_loss: 2.3045 - val_accuracy: 0.1081\n",
      "Epoch 21/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2442 - accuracy: 0.3315 - val_loss: 2.3046 - val_accuracy: 0.1047\n",
      "Epoch 22/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2406 - accuracy: 0.3433 - val_loss: 2.3045 - val_accuracy: 0.1081\n",
      "Epoch 23/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2369 - accuracy: 0.3573 - val_loss: 2.3043 - val_accuracy: 0.1047\n",
      "Epoch 24/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2332 - accuracy: 0.3564 - val_loss: 2.3041 - val_accuracy: 0.1047\n",
      "Epoch 25/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2293 - accuracy: 0.3729 - val_loss: 2.3043 - val_accuracy: 0.1047\n",
      "Epoch 26/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2253 - accuracy: 0.3796 - val_loss: 2.3040 - val_accuracy: 0.1014\n",
      "Epoch 27/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2212 - accuracy: 0.3826 - val_loss: 2.3038 - val_accuracy: 0.1047\n",
      "Epoch 28/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2169 - accuracy: 0.3932 - val_loss: 2.3035 - val_accuracy: 0.1014\n",
      "Epoch 29/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2125 - accuracy: 0.4096 - val_loss: 2.3035 - val_accuracy: 0.1047\n",
      "Epoch 30/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2080 - accuracy: 0.4092 - val_loss: 2.3032 - val_accuracy: 0.1047\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a2ebe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 2.3025 - accuracy: 0.0997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3025319576263428, 0.09966777265071869]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bca150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
