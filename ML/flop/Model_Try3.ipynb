{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import wave\n",
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "['recordings/7_yweweler_6.wav', 'recordings/5_george_9.wav', 'recordings/6_yweweler_48.wav', 'recordings/3_george_11.wav', 'recordings/8_nicolas_31.wav']\n"
     ]
    }
   ],
   "source": [
    "# shuffle filenames\n",
    "\n",
    "data_dir = \"recordings\"\n",
    "\n",
    "filenames = glob.glob(str(data_dir) + \"/*\")\n",
    "random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "\n",
    "print(num_samples)\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 2400\n",
      "Validation set size 300\n",
      "Test set size 300\n"
     ]
    }
   ],
   "source": [
    "tenth = int(num_samples * 0.1)\n",
    "eightyth = tenth * 8\n",
    "\n",
    "train_files = filenames[:eightyth]\n",
    "val_files = filenames[eightyth: eightyth + tenth]\n",
    "test_files = filenames[eightyth + tenth:]\n",
    "\n",
    "print('Training set size', len(train_files))\n",
    "print('Validation set size', len(val_files))\n",
    "print('Test set size', len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_audio(file_path):\n",
    "    # Read file to get buffer                                                                                               \n",
    "    ifile = wave.open(file_path)\n",
    "    samples = ifile.getnframes()\n",
    "    audio = ifile.readframes(samples)\n",
    "\n",
    "    # Convert buffer to float32 using NumPy                                                                                 \n",
    "    audio_as_np_int16 = np.frombuffer(audio, dtype=np.int16)\n",
    "    audio_as_np_float32 = audio_as_np_int16.astype(np.float32)\n",
    "\n",
    "    # Normalise float32 array so that values are between -1.0 and +1.0                                                      \n",
    "    max_int16 = 2**15\n",
    "    audio_normalised = audio_as_np_float32 / max_int16\n",
    "    \n",
    "    return audio_normalised\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = file_path.split(\"/\")\n",
    "    \n",
    "    label = int(parts[1].split(\"_\")[0])\n",
    "    \n",
    "    # Note: You'll use indexing here instead of tuple unpacking to enable this\n",
    "    # to work in a TensorFlow graph.\n",
    "    return label\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "#     audio_binary = tf.io.read_file(file_path)\n",
    "    waveform = decode_audio(file_path)\n",
    "#     return waveform, label\n",
    "    return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.0000000e+00,  9.1552734e-05,  1.2207031e-04, ...,\n",
      "       -3.9367676e-03, -3.8452148e-03, -3.1127930e-03], dtype=float32), 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminewu/Documents/6115/II/Spoken_Digits/venv/lib/python3.7/site-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class DatasetV2 with abstract methods _inputs, element_spec",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vs/b_y62_cj4859tj4h1ch0glg80000gn/T/ipykernel_3433/2042282052.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class DatasetV2 with abstract methods _inputs, element_spec"
     ]
    }
   ],
   "source": [
    "labeled = []\n",
    "\n",
    "for file_path in train_files:\n",
    "    datapoint = get_waveform_and_label(file_path)\n",
    "    print(datapoint)\n",
    "    labeled.append(datapoint)\n",
    "    break\n",
    "\n",
    "    \n",
    "l2 = np.array(labeled)\n",
    "tf.data.Dataset(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
