{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4859548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import wave\n",
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "# Set the seed value for experiment reproducibility.\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f726f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "['recordings/1_yweweler_14.wav', 'recordings/8_jackson_11.wav', 'recordings/2_lucas_5.wav', 'recordings/3_lucas_26.wav', 'recordings/7_nicolas_21.wav']\n"
     ]
    }
   ],
   "source": [
    "# shuffle filenames\n",
    "\n",
    "data_dir = \"recordings\"\n",
    "\n",
    "filenames = glob.glob(str(data_dir) + \"/*\")\n",
    "random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "\n",
    "print(num_samples)\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0840a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/audio/simple_audio\n",
    "\n",
    "def decode_audio(file_path):\n",
    "    # Read file to get buffer                                                                                               \n",
    "    ifile = wave.open(file_path)\n",
    "    samples = ifile.getnframes()\n",
    "    audio = ifile.readframes(samples)\n",
    "\n",
    "    # Convert buffer to float32 using NumPy                                                                                 \n",
    "    audio_as_np_int16 = np.frombuffer(audio, dtype=np.int16)\n",
    "    audio_as_np_float32 = audio_as_np_int16.astype(np.float32)\n",
    "\n",
    "    # Normalise float32 array so that values are between -1.0 and +1.0                                                      \n",
    "    max_int16 = 2**15\n",
    "    audio_normalized = audio_as_np_float32 / max_int16\n",
    "        \n",
    "    return audio_normalized\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = file_path.split(\"/\")\n",
    "    \n",
    "    label = int(parts[1].split(\"_\")[0])\n",
    "    \n",
    "    # Note: You'll use indexing here instead of tuple unpacking to enable this\n",
    "    # to work in a TensorFlow graph.\n",
    "    return label\n",
    "\n",
    "# def get_waveform_and_label(file_path):\n",
    "#     label = get_label(file_path)\n",
    "#     waveform = decode_audio(file_path)\n",
    "#     return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b79f56e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499.4746666666665\n",
      "1180.9471707171701\n",
      "7042\n"
     ]
    }
   ],
   "source": [
    "labeled = []\n",
    "\n",
    "lengths = np.array([])\n",
    "\n",
    "for file_path in filenames:\n",
    "    x_val = decode_audio(file_path)\n",
    "    y_val = get_label(file_path)\n",
    "    labeled.append((x_val, y_val))\n",
    "    lengths = np.append(lengths, x_val.shape[0])\n",
    "\n",
    "max_length = int(np.mean(lengths) + 3 * np.std(lengths))\n",
    "print(np.mean(lengths))\n",
    "print(np.std(lengths))\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ec43109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2965\n"
     ]
    }
   ],
   "source": [
    "# padding function from\n",
    "# https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5\n",
    "\n",
    "X_full = []\n",
    "y_full = []\n",
    "\n",
    "numbers = [0] * 10\n",
    "\n",
    "for x_val, y_val in labeled:\n",
    "    signal_length = x_val.shape[0]\n",
    "    if signal_length > max_length:\n",
    "        numbers[y_val] += 1\n",
    "    else:\n",
    "#         pad_begin_len = random.randint(0, max_length - signal_length)\n",
    "        pad_begin_len = 0\n",
    "        pad_end_len = max_length - signal_length - pad_begin_len\n",
    "        \n",
    "        new_x_val = np.pad(\n",
    "            x_val, (pad_begin_len, pad_end_len), \n",
    "            'constant', constant_values=(0, 0))\n",
    "        \n",
    "        X_full.append(new_x_val)\n",
    "        y_full.append(y_val)\n",
    "\n",
    "X_full = np.array(X_full)\n",
    "y_full = np.array(y_full)\n",
    "\n",
    "num_samples = X_full.shape[0]\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1350616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y  quantities\n",
      "0  0           4\n",
      "1  1           3\n",
      "2  2           5\n",
      "3  3           3\n",
      "4  4           1\n",
      "5  5           3\n",
      "6  6           2\n",
      "7  7           7\n",
      "8  8           3\n",
      "9  9           4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quantities = {\"y\": list(range(10)), \"quantities\": numbers}\n",
    "df = pd.DataFrame.from_dict(quantities)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e77497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 2368\n",
      "Validation set size 296\n",
      "Test set size 301\n"
     ]
    }
   ],
   "source": [
    "tenth = int(num_samples * 0.1)\n",
    "eightyth = tenth * 8\n",
    "\n",
    "X_train = X_full[:eightyth]\n",
    "y_train = y_full[:eightyth]\n",
    "\n",
    "X_val = X_full[eightyth: eightyth + tenth]\n",
    "y_val = y_full[eightyth: eightyth + tenth]\n",
    "\n",
    "X_test = X_full[eightyth + tenth:]\n",
    "y_test = y_full[eightyth + tenth:]\n",
    "\n",
    "print('Training set size', len(X_train))\n",
    "print('Validation set size', len(X_val))\n",
    "print('Test set size', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a5a438f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 300)               2112900   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,144,010\n",
      "Trainable params: 2,144,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\", input_shape=(7042,)))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# alternatively:\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     keras.layers.Dense(300, activation=\"relu\"),\n",
    "#     keras.layers.Dense(100, activation=\"relu\"),\n",
    "#     keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44f1598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0bd417e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "74/74 [==============================] - 1s 5ms/step - loss: 2.3036 - accuracy: 0.1039 - val_loss: 2.3016 - val_accuracy: 0.0608\n",
      "Epoch 2/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.3002 - accuracy: 0.1132 - val_loss: 2.3012 - val_accuracy: 0.0946\n",
      "Epoch 3/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2968 - accuracy: 0.1343 - val_loss: 2.3008 - val_accuracy: 0.0980\n",
      "Epoch 4/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2937 - accuracy: 0.1394 - val_loss: 2.3006 - val_accuracy: 0.1014\n",
      "Epoch 5/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2906 - accuracy: 0.1478 - val_loss: 2.3003 - val_accuracy: 0.1014\n",
      "Epoch 6/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2875 - accuracy: 0.1643 - val_loss: 2.3000 - val_accuracy: 0.1047\n",
      "Epoch 7/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2845 - accuracy: 0.1681 - val_loss: 2.2996 - val_accuracy: 0.1047\n",
      "Epoch 8/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2815 - accuracy: 0.1850 - val_loss: 2.2992 - val_accuracy: 0.1115\n",
      "Epoch 9/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2785 - accuracy: 0.1913 - val_loss: 2.2989 - val_accuracy: 0.1149\n",
      "Epoch 10/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2755 - accuracy: 0.2111 - val_loss: 2.2986 - val_accuracy: 0.1182\n",
      "Epoch 11/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2724 - accuracy: 0.2264 - val_loss: 2.2982 - val_accuracy: 0.1149\n",
      "Epoch 12/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2694 - accuracy: 0.2323 - val_loss: 2.2978 - val_accuracy: 0.1115\n",
      "Epoch 13/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2662 - accuracy: 0.2399 - val_loss: 2.2976 - val_accuracy: 0.1216\n",
      "Epoch 14/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2630 - accuracy: 0.2576 - val_loss: 2.2972 - val_accuracy: 0.1115\n",
      "Epoch 15/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2598 - accuracy: 0.2753 - val_loss: 2.2968 - val_accuracy: 0.1216\n",
      "Epoch 16/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2565 - accuracy: 0.2732 - val_loss: 2.2964 - val_accuracy: 0.1182\n",
      "Epoch 17/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2531 - accuracy: 0.2859 - val_loss: 2.2961 - val_accuracy: 0.1351\n",
      "Epoch 18/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2496 - accuracy: 0.3053 - val_loss: 2.2958 - val_accuracy: 0.1284\n",
      "Epoch 19/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2460 - accuracy: 0.3104 - val_loss: 2.2954 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2424 - accuracy: 0.3235 - val_loss: 2.2950 - val_accuracy: 0.1318\n",
      "Epoch 21/30\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 2.2386 - accuracy: 0.3349 - val_loss: 2.2944 - val_accuracy: 0.1385\n",
      "Epoch 22/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2347 - accuracy: 0.3353 - val_loss: 2.2941 - val_accuracy: 0.1318\n",
      "Epoch 23/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2307 - accuracy: 0.3530 - val_loss: 2.2935 - val_accuracy: 0.1385\n",
      "Epoch 24/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2266 - accuracy: 0.3556 - val_loss: 2.2931 - val_accuracy: 0.1351\n",
      "Epoch 25/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2223 - accuracy: 0.3670 - val_loss: 2.2926 - val_accuracy: 0.1385\n",
      "Epoch 26/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2179 - accuracy: 0.3712 - val_loss: 2.2920 - val_accuracy: 0.1419\n",
      "Epoch 27/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2133 - accuracy: 0.3906 - val_loss: 2.2916 - val_accuracy: 0.1419\n",
      "Epoch 28/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2087 - accuracy: 0.3919 - val_loss: 2.2911 - val_accuracy: 0.1453\n",
      "Epoch 29/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.2039 - accuracy: 0.4046 - val_loss: 2.2905 - val_accuracy: 0.1419\n",
      "Epoch 30/30\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 2.1989 - accuracy: 0.4130 - val_loss: 2.2899 - val_accuracy: 0.1419\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9a2ebe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 2.2964 - accuracy: 0.0963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2964041233062744, 0.09634551405906677]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bca150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
